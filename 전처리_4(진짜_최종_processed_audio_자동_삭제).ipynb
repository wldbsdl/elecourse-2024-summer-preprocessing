{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA2iEKt7IJLE",
        "outputId": "da2dc519-6818-4df1-b24e-c18322bd055d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install pydub\n",
        "!apt-get install ffmpeg\n",
        "!pip install librosa matplotlib numpy\n",
        "\n",
        "# Import required libraries\n",
        "from google.colab import drive\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "\n",
        "# Mapping of emotion identifiers to their corresponding labels\n",
        "emotion_map = {\n",
        "    '01': 'neutral',\n",
        "    '02': 'calm',\n",
        "    '03': 'happy',\n",
        "    '04': 'sad',\n",
        "    '05': 'angry',\n",
        "    '06': 'fearful',\n",
        "    '07': 'disgust',\n",
        "    '08': 'surprised'\n",
        "}\n",
        "\n",
        "# Function to extract features from audio files and pad/truncate to a fixed length\n",
        "def extract_features(audio, sr=22050, feature_type='mfcc', num_features=40, delta=False, max_pad_len=431):\n",
        "    if len(audio) == 0:\n",
        "        print(\"Empty audio signal encountered.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        if feature_type == 'mfcc':\n",
        "            features = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_features)\n",
        "        elif feature_type == 'mel':\n",
        "            features = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=num_features)\n",
        "        elif feature_type == 'stft':\n",
        "            features = np.abs(librosa.stft(y=audio, n_fft=512))\n",
        "\n",
        "        if delta:\n",
        "            delta_feat = librosa.feature.delta(features)\n",
        "            delta_delta_feat = librosa.feature.delta(features, order=2)\n",
        "            features = np.concatenate((features, delta_feat, delta_delta_feat), axis=0)\n",
        "\n",
        "        features = np.clip(features, a_min=-1e10, a_max=1e10)\n",
        "\n",
        "        if features.shape[1] > max_pad_len:\n",
        "            features = features[:, :max_pad_len]\n",
        "        else:\n",
        "            pad_width = max_pad_len - features.shape[1]\n",
        "            features = np.pad(features, ((0, 0), (0, pad_width)), mode='constant')\n",
        "\n",
        "        features = np.nan_to_num(features)\n",
        "\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting features: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to load data using a list of audio files\n",
        "def load_data(audio_files, feature_types=['mfcc', 'mel', 'stft'], num_features=40, delta=False, max_pad_len=431):\n",
        "    data_dict = {feature_type: [] for feature_type in feature_types}\n",
        "    labels_list = []\n",
        "    for file_path in audio_files:\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                print(f'File does not exist: {file_path}')\n",
        "                continue\n",
        "            label = file_path.split('/')[-1].split('-')[2]\n",
        "            audio, sr = librosa.load(file_path, sr=None)\n",
        "            if len(audio) == 0:\n",
        "                print(f'Empty audio file: {file_path}')\n",
        "                continue\n",
        "            for feature_type in feature_types:\n",
        "                features = extract_features(audio, sr=sr, feature_type=feature_type, num_features=num_features, delta=delta, max_pad_len=max_pad_len)\n",
        "                if features is not None and features.shape[1] > 0:\n",
        "                    data_dict[feature_type].append(features)\n",
        "            labels_list.append(label)\n",
        "        except Exception as e:\n",
        "            print(f'Error processing {file_path}: {e}')\n",
        "    return {feature_type: np.array(data_dict[feature_type]) for feature_type in feature_types}, np.array(labels_list)\n",
        "\n",
        "# Function to plot and save a spectrogram\n",
        "def plot_spectrogram(spectrogram, label, save_path=None):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    if spectrogram.ndim == 2:\n",
        "        plt.imshow(librosa.power_to_db(spectrogram, ref=np.max), aspect='auto', origin='lower', cmap='viridis')\n",
        "    elif spectrogram.ndim == 3:\n",
        "        plt.imshow(librosa.power_to_db(spectrogram[:, :, 0], ref=np.max), aspect='auto', origin='lower', cmap='viridis')\n",
        "    plt.title(f'Label: {label}')\n",
        "    plt.ylabel('Frequency bins')\n",
        "    plt.xlabel('Time frames')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "        print(f\"Saved spectrogram to {save_path}\")\n",
        "\n",
        "# Function to get all audio files including those in subdirectories\n",
        "def get_audio_files(root_dir):\n",
        "    audio_files = []\n",
        "    for subdir, _, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav'):\n",
        "                audio_files.append(os.path.join(subdir, file))\n",
        "    return audio_files\n",
        "\n",
        "# Function to generate and save spectrogram images for all audio files\n",
        "def generate_spectrograms_for_all_files(data_dict, output_dir, feature_types):\n",
        "    for feature_type in feature_types:\n",
        "        for idx, file_path in enumerate(audio_files):\n",
        "            try:\n",
        "                file_name = os.path.basename(file_path).split('.')[0]\n",
        "                emotion = emotion_map.get(file_path.split('/')[-1].split('-')[2], 'Unknown')\n",
        "                if idx < len(data_dict[feature_type]):\n",
        "                    save_path = os.path.join(output_dir, f\"{file_name}_{feature_type.upper()}.png\")\n",
        "                    print(f\"Generating image for file {file_name} and feature type {feature_type}.\")\n",
        "                    plot_spectrogram(data_dict[feature_type][idx].squeeze(axis=0), emotion, save_path=save_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating spectrogram for {file_path}: {e}\")\n",
        "\n",
        "# Google Drive mount and directory setup\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Google Drive path setup\n",
        "input_dir = '/content/drive/MyDrive/ELECOURSE/audio_files'  # Path where audio files are stored\n",
        "output_dir = '/content/drive/MyDrive/ELECOURSE/processed_audio'  # Path to save processed files\n",
        "\n",
        "# Remove existing processed_audio folder if it exists\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "\n",
        "# Create new processed_audio folder\n",
        "os.makedirs(output_dir)\n",
        "\n",
        "# Define audio file list\n",
        "audio_files = get_audio_files(input_dir)\n",
        "\n",
        "# Check audio file paths\n",
        "if not audio_files:\n",
        "    print(\"No audio files found in the specified directory.\")\n",
        "else:\n",
        "    print(f\"Found {len(audio_files)} audio files.\")\n",
        "\n",
        "# Load and preprocess data\n",
        "feature_types = ['mfcc', 'mel', 'stft']\n",
        "data_dict, y = load_data(audio_files, feature_types=feature_types, num_features=40, delta=True)\n",
        "\n",
        "if all(data.size == 0 for data in data_dict.values()) or y.size == 0:\n",
        "    print(\"No data loaded. Please check the feature extraction process.\")\n",
        "else:\n",
        "    for feature_type, X in data_dict.items():\n",
        "        print(f\"Loaded X shape for {feature_type}: {X.shape}\")\n",
        "    print(f\"Loaded y shape: {y.shape}\")\n",
        "\n",
        "    # Label encoding\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "    # Convert to 4D tensor (add channel dimension)\n",
        "    for feature_type, X in data_dict.items():\n",
        "        X = X[..., np.newaxis]  # Add channel axis\n",
        "        X = np.expand_dims(X, axis=1)  # Add batch axis\n",
        "        data_dict[feature_type] = X\n",
        "\n",
        "    # Generate spectrogram images for all audio files\n",
        "    generate_spectrograms_for_all_files(data_dict, output_dir, feature_types)\n",
        "\n",
        "# User input for zip file name\n",
        "zip_filename = input(\"Enter the filename for the zip file (without extension): \")\n",
        "\n",
        "# Compress and download image files\n",
        "shutil.make_archive(zip_filename, 'zip', output_dir)\n",
        "files.download(f\"{zip_filename}.zip\")\n"
      ]
    }
  ]
}